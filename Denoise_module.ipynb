{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b6bfd5-6965-4d54-9300-692f7c45bdee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Import necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2f3f42-78af-4aeb-8f12-e4cd7f45ba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Master\\Thesis\\FRCRN\\Summary\\metrics_utils.py:50: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lpcoeff(speech_frame, model_order):\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\noise_addition_utils.py:15: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu118\n",
      "2.1.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from pathlib import Path\n",
    "\n",
    "from metrics import AudioMetrics\n",
    "from metrics import AudioMetrics2\n",
    "#from Audio_metrics import AudioMetrics2\n",
    "import noise_addition_utils\n",
    "from pypesq import pesq\n",
    "import shutil\n",
    "\n",
    "\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "#import tarfile\n",
    "import multiprocessing\n",
    "\n",
    "import scipy\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "import requests\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a30e4c0c-8271-46c7-9e0c-78ad266f4b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# Helper functions.\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "def denoise_audio(input_path, output_path, smoothing_factor):\n",
    "    # Load the audio file\n",
    "    snd = parselmouth.Sound(input_path)\n",
    "\n",
    "    # Apply smoothing to reduce noise\n",
    "    snd_denoised = snd.copy()\n",
    "    #snd_denoised = call(snd_denoised, \"Smooth\", smoothing_factor)\n",
    "    snd_denoised = call(snd_denoised, \"Reduce noise\", 0.0, 0.0, 0.025, 80.0, 10000.0, 40.0,-20, \"Spectral-subtraction\")\n",
    "    # Save the denoised audio\n",
    "    snd_denoised.save(output_path, \"WAV\")\n",
    "def get_stats(waveform, sample_rate=None, src=None):\n",
    "    max_ = waveform.max().numpy()\n",
    "    min_ = waveform.min().numpy()\n",
    "    mean_ = waveform.mean().numpy()\n",
    "    std_ = waveform.std().numpy()\n",
    "    return max_,min_,mean_,std_\n",
    "\n",
    "def print_stats(waveform, sample_rate=None, src=None):\n",
    "    if src:\n",
    "        print(\"-\" * 10)\n",
    "        print(\"Source:\", src)\n",
    "        print(\"-\" * 10)\n",
    "    if sample_rate:\n",
    "        print(\"Sample Rate:\", sample_rate)\n",
    "        print(\"Shape:\", tuple(waveform.shape))\n",
    "        print(\"Dtype:\", waveform.dtype)\n",
    "        print(f\" - Max:     {waveform.max().item():6.3f}\")\n",
    "        print(f\" - Min:     {waveform.min().item():6.3f}\")\n",
    "        print(f\" - Mean:    {waveform.mean().item():6.3f}\")\n",
    "        print(f\" - Std Dev: {waveform.std().item():6.3f}\")\n",
    "        print()\n",
    "        print(waveform)\n",
    "        print()\n",
    "    # max_ = waveform.max().numpy()\n",
    "    # min_ = waveform.min().numpy()\n",
    "    # mean_ = waveform.mean().numpy()\n",
    "    # std_ = waveform.std().numpy()\n",
    "    # return max_,min_,mean_,std_\n",
    "\n",
    "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n",
    "  waveform = waveform.numpy()\n",
    "\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "  figure, axes = plt.subplots(num_channels, 1)\n",
    "  if num_channels == 1:\n",
    "    axes = [axes]\n",
    "  for c in range(num_channels):\n",
    "    axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "    axes[c].grid(True)\n",
    "    if num_channels > 1:\n",
    "      axes[c].set_ylabel(f'Channel {c+1}')\n",
    "    if xlim:\n",
    "      axes[c].set_xlim(xlim)\n",
    "    if ylim:\n",
    "      axes[c].set_ylim(ylim)\n",
    "  figure.suptitle(title)\n",
    "  plt.show(block=False)\n",
    "\n",
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
    "  waveform = waveform.numpy()\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "  figure, axes = plt.subplots(num_channels, 1)\n",
    "  if num_channels == 1:\n",
    "    axes = [axes]\n",
    "  for c in range(num_channels):\n",
    "    axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "    if num_channels > 1:\n",
    "      axes[c].set_ylabel(f'Channel {c+1}')\n",
    "    if xlim:\n",
    "      axes[c].set_xlim(xlim)\n",
    "  figure.suptitle(title)\n",
    "  plt.show(block=False)\n",
    "\n",
    "def play_audio(waveform, sample_rate):\n",
    "  waveform = waveform.numpy()\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  if num_channels == 1:\n",
    "    display(Audio(waveform[0], rate=sample_rate))\n",
    "  elif num_channels == 2:\n",
    "    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
    "  else:\n",
    "    raise ValueError(\"Waveform with more than 2 channels are not supported.\")\n",
    "\n",
    "def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n",
    "  fig, axs = plt.subplots(1, 1)\n",
    "  axs.set_title(title or 'Spectrogram (db)')\n",
    "  axs.set_ylabel(ylabel)\n",
    "  axs.set_xlabel('frame')\n",
    "  im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect)\n",
    "  if xmax:\n",
    "    axs.set_xlim((0, xmax))\n",
    "  fig.colorbar(im, ax=axs)\n",
    "  plt.show(block=False)\n",
    "\n",
    "def get_spectrogram(\n",
    "    n_fft = 400,\n",
    "    win_len = None,\n",
    "    hop_len = None,\n",
    "    power = 2.0,\n",
    "):\n",
    "  waveform, _ = get_speech_sample()\n",
    "  spectrogram = T.Spectrogram(\n",
    "      n_fft=n_fft,\n",
    "      win_length=win_len,\n",
    "      hop_length=hop_len,\n",
    "      center=True,\n",
    "      pad_mode=\"reflect\",\n",
    "      power=power,\n",
    "  )\n",
    "  return spectrogram(waveform)\n",
    "def resample_wav_files(input_path, output_path, target_sr):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Get a list of all WAV files in the input directory and its subfolders\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.wav'):\n",
    "                # Read the input WAV file\n",
    "                input_file = os.path.join(root, file_name)\n",
    "                audio, sr = librosa.load(input_file, sr=target_sr)\n",
    "\n",
    "                # Write the resampled audio to the output WAV file\n",
    "                output_dir = os.path.join(output_path, os.path.relpath(root, input_path))\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                output_file = os.path.join(output_dir, file_name)\n",
    "                sf.write(output_file, audio, target_sr)\n",
    "def copy_wav_files_to_single_directory(input_path, output_path):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Get a list of all WAV files in the input directory and its subfolders\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.wav'):\n",
    "                # Copy the WAV file to the output directory with the original filename\n",
    "                input_file = os.path.join(root, file_name)\n",
    "                output_file = os.path.join(output_path, file_name)\n",
    "                shutil.copy2(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff8aa7-a05d-4d2c-9f26-e23070505318",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Spectral Subtraction method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908405dd-421d-41b5-8c50-2893fb299d81",
   "metadata": {},
   "source": [
    "#### Define the path to denoise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c40240e-bf2c-496f-94fc-460d8b9087b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Master/Thesis/FRCRN/Summary/Test/0001.1.wav')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahna_dataset = sorted(list(Path(r\"D:\\Master\\Thesis\\FRCRN\\Summary\\Test\").rglob('*.wav')))\n",
    "bahna_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6755c0-a67e-4637-9416-8e68184977ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Noise_level_before_denoised</th>\n",
       "      <th>Max_after_denoised</th>\n",
       "      <th>Min_after_denoised</th>\n",
       "      <th>Mean_after_denoised</th>\n",
       "      <th>Std_after_denoised</th>\n",
       "      <th>Noise_level_after_denoised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Max, Min, Mean, Std, Noise_level_before_denoised, Max_after_denoised, Min_after_denoised, Mean_after_denoised, Std_after_denoised, Noise_level_after_denoised]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe to record statistics\n",
    "stat_bahna_spectral_subtraction = pd.DataFrame(columns=['Name','Max', 'Min', 'Mean','Std','Noise_level_before_denoised','Max_after_denoised', 'Min_after_denoised', 'Mean_after_denoised','Std_after_denoised','Noise_level_after_denoised'])\n",
    "stat_bahna_spectral_subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c68dd6d-f6f7-43c7-a748-9e6d1215d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.1.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.1_spectral_subtraction_denoised.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.2.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.2_spectral_subtraction_denoised.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.3.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.3_spectral_subtraction_denoised.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.4.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.4_spectral_subtraction_denoised.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.5.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.5_spectral_subtraction_denoised.wav\n"
     ]
    }
   ],
   "source": [
    "for i in bahna_dataset:\n",
    "    print(i)\n",
    "    waveform, sample_rate = torchaudio.load(i)\n",
    "    max_,min_,mean_,std_ = get_stats(waveform, sample_rate = sample_rate)\n",
    "    if std_!=0 :\n",
    "        noise_level = 10*( np.log10(std_/max_))\n",
    "    else:\n",
    "        noise_level = 0\n",
    "    normalized_path = os.path.normpath(i)\n",
    "    input_path = os.path.splitext(normalized_path)[0] + os.path.splitext(normalized_path)[1]\n",
    "    denoised_path = os.path.splitext(normalized_path)[0] + \"_spectral_subtraction_denoised\" + os.path.splitext(normalized_path)[1]\n",
    "    snd = parselmouth.Sound(input_path)\n",
    "    snd_denoised = snd.copy()\n",
    "    snd_denoised = call(snd_denoised, \"Reduce noise\", 0.0, 0.0, 0.025, 80.0, 10000.0, 40.0,noise_level, \"Spectral-subtraction\")\n",
    "    # Save the denoised audio\n",
    "    snd_denoised.save(denoised_path, \"WAV\")\n",
    "    print(denoised_path)\n",
    "    waveform_denoised, sample_rate_denoised = torchaudio.load(denoised_path)\n",
    "    max_after,min_after,mean_after,std_after=get_stats(waveform_denoised, sample_rate=sample_rate_denoised)\n",
    "    if std_after!=0 :\n",
    "        noise_level_after = 10*( np.log10(std_after/max_after))\n",
    "    else:\n",
    "        noise_level_after = 0\n",
    "    df = pd.DataFrame({\"Name\":[i],\"Max\":[max_],\"Min\":[min_],\"Mean\":[mean_],\"Std\":[std_],\"Noise_level_before_denoised\":[noise_level],'Max_after_denoised':[max_after], 'Min_after_denoised':[min_after], 'Mean_after_denoised':[mean_after],'Std_after_denoised':[std_after],'Noise_level_after_denoised':[noise_level_after]})\n",
    "    stat_bahna_spectral_subtraction=pd.concat([stat_bahna_spectral_subtraction,df], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4b6c8f2-cbd5-4b99-8ce1-a4f222301f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Noise_level_before_denoised</th>\n",
       "      <th>Max_after_denoised</th>\n",
       "      <th>Min_after_denoised</th>\n",
       "      <th>Mean_after_denoised</th>\n",
       "      <th>Std_after_denoised</th>\n",
       "      <th>Noise_level_after_denoised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.1.wav</td>\n",
       "      <td>0.6552124</td>\n",
       "      <td>-0.7651062</td>\n",
       "      <td>-3.0624975e-05</td>\n",
       "      <td>0.07685376</td>\n",
       "      <td>-9.307170</td>\n",
       "      <td>0.6543884</td>\n",
       "      <td>-0.76400757</td>\n",
       "      <td>6.9447053e-09</td>\n",
       "      <td>0.07664716</td>\n",
       "      <td>-9.313395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.2.wav</td>\n",
       "      <td>0.55578613</td>\n",
       "      <td>-0.4998474</td>\n",
       "      <td>-3.9136925e-05</td>\n",
       "      <td>0.0951897</td>\n",
       "      <td>-7.663178</td>\n",
       "      <td>0.5445862</td>\n",
       "      <td>-0.47906494</td>\n",
       "      <td>8.370825e-07</td>\n",
       "      <td>0.09144629</td>\n",
       "      <td>-7.749005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.3.wav</td>\n",
       "      <td>0.47247314</td>\n",
       "      <td>-0.53967285</td>\n",
       "      <td>-2.9462188e-05</td>\n",
       "      <td>0.048951853</td>\n",
       "      <td>-9.846080</td>\n",
       "      <td>0.45462036</td>\n",
       "      <td>-0.49050903</td>\n",
       "      <td>1.8565483e-05</td>\n",
       "      <td>0.04017664</td>\n",
       "      <td>-10.536753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.4.wav</td>\n",
       "      <td>0.4461975</td>\n",
       "      <td>-0.56170654</td>\n",
       "      <td>-4.4831922e-05</td>\n",
       "      <td>0.059409264</td>\n",
       "      <td>-8.756730</td>\n",
       "      <td>0.4430542</td>\n",
       "      <td>-0.55825806</td>\n",
       "      <td>-3.5348178e-06</td>\n",
       "      <td>0.058748286</td>\n",
       "      <td>-8.774617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.5.wav</td>\n",
       "      <td>0.32443237</td>\n",
       "      <td>-0.37664795</td>\n",
       "      <td>-1.7288974e-05</td>\n",
       "      <td>0.046413366</td>\n",
       "      <td>-8.444811</td>\n",
       "      <td>0.32302856</td>\n",
       "      <td>-0.37149048</td>\n",
       "      <td>1.2664118e-06</td>\n",
       "      <td>0.04507507</td>\n",
       "      <td>-8.553045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name         Max          Min  \\\n",
       "0  D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.1.wav   0.6552124   -0.7651062   \n",
       "1  D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.2.wav  0.55578613   -0.4998474   \n",
       "2  D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.3.wav  0.47247314  -0.53967285   \n",
       "3  D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.4.wav   0.4461975  -0.56170654   \n",
       "4  D:\\Master\\Thesis\\FRCRN\\Summary\\Test\\0001.5.wav  0.32443237  -0.37664795   \n",
       "\n",
       "             Mean          Std  Noise_level_before_denoised  \\\n",
       "0  -3.0624975e-05   0.07685376                    -9.307170   \n",
       "1  -3.9136925e-05    0.0951897                    -7.663178   \n",
       "2  -2.9462188e-05  0.048951853                    -9.846080   \n",
       "3  -4.4831922e-05  0.059409264                    -8.756730   \n",
       "4  -1.7288974e-05  0.046413366                    -8.444811   \n",
       "\n",
       "  Max_after_denoised Min_after_denoised Mean_after_denoised  \\\n",
       "0          0.6543884        -0.76400757       6.9447053e-09   \n",
       "1          0.5445862        -0.47906494        8.370825e-07   \n",
       "2         0.45462036        -0.49050903       1.8565483e-05   \n",
       "3          0.4430542        -0.55825806      -3.5348178e-06   \n",
       "4         0.32302856        -0.37149048       1.2664118e-06   \n",
       "\n",
       "  Std_after_denoised  Noise_level_after_denoised  \n",
       "0         0.07664716                   -9.313395  \n",
       "1         0.09144629                   -7.749005  \n",
       "2         0.04017664                  -10.536753  \n",
       "3        0.058748286                   -8.774617  \n",
       "4         0.04507507                   -8.553045  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_bahna_spectral_subtraction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a49cb02-612c-4f70-a7eb-c835e983609d",
   "metadata": {},
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31530017-c342-41da-ad7c-e573c18e8161",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### FRCRN method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d55f98-2e3e-40f0-b5ec-3fda6a5195eb",
   "metadata": {},
   "source": [
    "This model use a fixed input with Sampling frequency is 16khz so we have to resample the input before we put it into our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e299eb1a-f3f0-4b81-b12c-f6a92babf4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage resample to 16khz\n",
    "input_directory = r'D:/Master/Thesis/FRCRN/Summary/Test/'\n",
    "output_directory = 'D:/Master/Thesis/FRCRN/Summary/Test resample'\n",
    "target_sampling_rate = 16000\n",
    "\n",
    "resample_wav_files(input_directory, output_directory, target_sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c509e1-e2d3-448f-8907-03183afb765c",
   "metadata": {},
   "source": [
    "#### Define path to denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7611030e-57df-4ad3-ad48-b5715c1b1545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Master/Thesis/FRCRN/Summary/Test resample/0001.1.wav')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahna_dataset_FRCRN = sorted(list(Path(r\"D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\").rglob('*.wav')))\n",
    "bahna_dataset_FRCRN[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb972edd-b18b-4bb7-a006-486a05456afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Noise_level_before_denoised</th>\n",
       "      <th>Max_after_denoised</th>\n",
       "      <th>Min_after_denoised</th>\n",
       "      <th>Mean_after_denoised</th>\n",
       "      <th>Std_after_denoised</th>\n",
       "      <th>Noise_level_after_denoised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Max, Min, Mean, Std, Noise_level_before_denoised, Max_after_denoised, Min_after_denoised, Mean_after_denoised, Std_after_denoised, Noise_level_after_denoised]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_bahna_FRCRN = pd.DataFrame(columns=['Name','Max', 'Min', 'Mean','Std','Noise_level_before_denoised','Max_after_denoised', 'Min_after_denoised', 'Mean_after_denoised','Std_after_denoised','Noise_level_after_denoised'])\n",
    "stat_bahna_FRCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20dd07c3-1261-4f81-884c-18d75e40eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12619a12-fb5b-47a2-b46d-935eb6204478",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 01:20:21,671 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.1\n",
      "2024-01-08 01:20:22,606 - modelscope - INFO - initiate model from C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k\n",
      "2024-01-08 01:20:22,606 - modelscope - INFO - initiate model from location C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k.\n",
      "2024-01-08 01:20:22,611 - modelscope - INFO - initialize model from C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k\n",
      "2024-01-08 01:20:23,298 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-01-08 01:20:23,298 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-01-08 01:20:23,306 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\PC\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\speech_frcrn_ans_cirm_16k'}. trying to build by task and model information.\n",
      "2024-01-08 01:20:23,307 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 104000)\n",
      "padding: 20000\n",
      "inputs after padding:(1, 124000)\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.1_denoised_FRCRN.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 01:20:25,936 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.1\n",
      "2024-01-08 01:20:26,466 - modelscope - INFO - initiate model from C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k\n",
      "2024-01-08 01:20:26,466 - modelscope - INFO - initiate model from location C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k.\n",
      "2024-01-08 01:20:26,470 - modelscope - INFO - initialize model from C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k\n",
      "2024-01-08 01:20:27,316 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-01-08 01:20:27,322 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-01-08 01:20:27,323 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\PC\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\speech_frcrn_ans_cirm_16k'}. trying to build by task and model information.\n",
      "2024-01-08 01:20:27,324 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 55913)\n",
      "padding: 19913\n",
      "inputs after padding:(1, 75826)\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.2_denoised_FRCRN.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 01:20:29,317 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.1\n",
      "2024-01-08 01:20:29,846 - modelscope - INFO - initiate model from C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k\n",
      "2024-01-08 01:20:29,846 - modelscope - INFO - initiate model from location C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k.\n",
      "2024-01-08 01:20:29,853 - modelscope - INFO - initialize model from C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k\n",
      "2024-01-08 01:20:30,576 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-01-08 01:20:30,576 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-01-08 01:20:30,576 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\PC\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\speech_frcrn_ans_cirm_16k'}. trying to build by task and model information.\n",
      "2024-01-08 01:20:30,580 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 27509)\n",
      "padding: 491\n",
      "inputs after padding:(1, 28000)\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.3_denoised_FRCRN.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 01:20:33,485 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.1\n",
      "2024-01-08 01:20:34,986 - modelscope - INFO - initiate model from C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k\n",
      "2024-01-08 01:20:34,986 - modelscope - INFO - initiate model from location C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k.\n",
      "2024-01-08 01:20:34,991 - modelscope - INFO - initialize model from C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k\n",
      "2024-01-08 01:20:35,695 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-01-08 01:20:35,697 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-01-08 01:20:35,698 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\PC\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\speech_frcrn_ans_cirm_16k'}. trying to build by task and model information.\n",
      "2024-01-08 01:20:35,698 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 42707)\n",
      "padding: 18707\n",
      "inputs after padding:(1, 61414)\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.4_denoised_FRCRN.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 01:20:37,844 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.1\n",
      "2024-01-08 01:20:38,376 - modelscope - INFO - initiate model from C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k\n",
      "2024-01-08 01:20:38,376 - modelscope - INFO - initiate model from location C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k.\n",
      "2024-01-08 01:20:38,389 - modelscope - INFO - initialize model from C:\\Users\\PC\\.cache\\modelscope\\hub\\damo\\speech_frcrn_ans_cirm_16k\n",
      "2024-01-08 01:20:39,092 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-01-08 01:20:39,092 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-01-08 01:20:39,092 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\PC\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\speech_frcrn_ans_cirm_16k'}. trying to build by task and model information.\n",
      "2024-01-08 01:20:39,095 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 31086)\n",
      "padding: 19086\n",
      "inputs after padding:(1, 50172)\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.5_denoised_FRCRN.wav\n"
     ]
    }
   ],
   "source": [
    "for i in bahna_dataset_FRCRN:\n",
    "    print(i)\n",
    "    waveform, sample_rate = torchaudio.load(i)\n",
    "    max_,min_,mean_,std_ = get_stats(waveform, sample_rate = sample_rate)\n",
    "    if std_!=0 :\n",
    "        noise_level = 10*( np.log10(std_/max_))\n",
    "    else:\n",
    "        noise_level = 0\n",
    "    # df = pd.DataFrame({\"Name\":[i],\"Std\":[std_],\"Noise_level\":[noise_level]})\n",
    "    # stat_bahna=pd.concat([stat_bahna,df], ignore_index=True)\n",
    "    normalized_path = os.path.normpath(i)\n",
    "    input_path = os.path.splitext(normalized_path)[0] + os.path.splitext(normalized_path)[1]\n",
    "    denoised_path = os.path.splitext(normalized_path)[0] + \"_denoised_FRCRN\" + os.path.splitext(normalized_path)[1]\n",
    "    \n",
    "    # denoised audio    \n",
    "    ans = pipeline(\n",
    "        Tasks.acoustic_noise_suppression,\n",
    "        model='damo/speech_frcrn_ans_cirm_16k')\n",
    "    result = ans(\n",
    "        str(i),\n",
    "        output_path=denoised_path)\n",
    "    print(denoised_path)\n",
    "    waveform_denoised, sample_rate_denoised = torchaudio.load(denoised_path)\n",
    "    max_after,min_after,mean_after,std_after=get_stats(waveform_denoised, sample_rate=sample_rate_denoised)\n",
    "    if std_after!=0 :\n",
    "        noise_level_after = 10*( np.log10(std_after/max_after))\n",
    "    else:\n",
    "        noise_level_after = 0\n",
    "    df_FRCRN = pd.DataFrame({\"Name\":[i],\"Max\":[max_],\"Min\":[min_],\"Mean\":[mean_],\"Std\":[std_],\"Noise_level_before_denoised\":[noise_level],'Max_after_denoised':[max_after], 'Min_after_denoised':[min_after], 'Mean_after_denoised':[mean_after],'Std_after_denoised':[std_after],'Noise_level_after_denoised':[noise_level_after]})\n",
    "    stat_bahna_FRCRN=pd.concat([stat_bahna_FRCRN,df_FRCRN], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9065f53-150e-40d9-ba58-0de8bd28ceb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Noise_level_before_denoised</th>\n",
       "      <th>Max_after_denoised</th>\n",
       "      <th>Min_after_denoised</th>\n",
       "      <th>Mean_after_denoised</th>\n",
       "      <th>Std_after_denoised</th>\n",
       "      <th>Noise_level_after_denoised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0...</td>\n",
       "      <td>0.6415405</td>\n",
       "      <td>-0.744812</td>\n",
       "      <td>-4.554191e-05</td>\n",
       "      <td>0.07685028</td>\n",
       "      <td>-9.215786</td>\n",
       "      <td>0.22348022</td>\n",
       "      <td>-0.2592163</td>\n",
       "      <td>-1.2544192e-05</td>\n",
       "      <td>0.02678586</td>\n",
       "      <td>-9.213335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0...</td>\n",
       "      <td>0.5562134</td>\n",
       "      <td>-0.5000305</td>\n",
       "      <td>-5.428519e-05</td>\n",
       "      <td>0.095189065</td>\n",
       "      <td>-7.666544</td>\n",
       "      <td>0.14968872</td>\n",
       "      <td>-0.14984131</td>\n",
       "      <td>-6.419209e-06</td>\n",
       "      <td>0.025932873</td>\n",
       "      <td>-7.613384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0...</td>\n",
       "      <td>0.4666748</td>\n",
       "      <td>-0.539917</td>\n",
       "      <td>-4.4708602e-05</td>\n",
       "      <td>0.048952047</td>\n",
       "      <td>-9.792435</td>\n",
       "      <td>0.25463867</td>\n",
       "      <td>-0.28683472</td>\n",
       "      <td>-1.7360486e-05</td>\n",
       "      <td>0.024598626</td>\n",
       "      <td>-10.150135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0...</td>\n",
       "      <td>0.446167</td>\n",
       "      <td>-0.56173706</td>\n",
       "      <td>-6.0049035e-05</td>\n",
       "      <td>0.059409186</td>\n",
       "      <td>-8.756438</td>\n",
       "      <td>0.19506836</td>\n",
       "      <td>-0.25405884</td>\n",
       "      <td>-1.7696579e-05</td>\n",
       "      <td>0.024957675</td>\n",
       "      <td>-8.929827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0...</td>\n",
       "      <td>0.31622314</td>\n",
       "      <td>-0.37667847</td>\n",
       "      <td>-3.2520275e-05</td>\n",
       "      <td>0.046413545</td>\n",
       "      <td>-8.333489</td>\n",
       "      <td>0.17993164</td>\n",
       "      <td>-0.2157898</td>\n",
       "      <td>-9.342977e-06</td>\n",
       "      <td>0.02612493</td>\n",
       "      <td>-8.380524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name         Max          Min  \\\n",
       "0  D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0...   0.6415405    -0.744812   \n",
       "1  D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0...   0.5562134   -0.5000305   \n",
       "2  D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0...   0.4666748    -0.539917   \n",
       "3  D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0...    0.446167  -0.56173706   \n",
       "4  D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0...  0.31622314  -0.37667847   \n",
       "\n",
       "             Mean          Std  Noise_level_before_denoised  \\\n",
       "0   -4.554191e-05   0.07685028                    -9.215786   \n",
       "1   -5.428519e-05  0.095189065                    -7.666544   \n",
       "2  -4.4708602e-05  0.048952047                    -9.792435   \n",
       "3  -6.0049035e-05  0.059409186                    -8.756438   \n",
       "4  -3.2520275e-05  0.046413545                    -8.333489   \n",
       "\n",
       "  Max_after_denoised Min_after_denoised Mean_after_denoised  \\\n",
       "0         0.22348022         -0.2592163      -1.2544192e-05   \n",
       "1         0.14968872        -0.14984131       -6.419209e-06   \n",
       "2         0.25463867        -0.28683472      -1.7360486e-05   \n",
       "3         0.19506836        -0.25405884      -1.7696579e-05   \n",
       "4         0.17993164         -0.2157898       -9.342977e-06   \n",
       "\n",
       "  Std_after_denoised  Noise_level_after_denoised  \n",
       "0         0.02678586                   -9.213335  \n",
       "1        0.025932873                   -7.613384  \n",
       "2        0.024598626                  -10.150135  \n",
       "3        0.024957675                   -8.929827  \n",
       "4         0.02612493                   -8.380524  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_bahna_FRCRN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2c3bc-5815-4c1c-85b6-3f679844afdd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Evaluation (PESQ, STOI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa62a9-70be-446c-a14a-47f1bb4f4d50",
   "metadata": {},
   "source": [
    "PESQ Score only support for sampling rate Fs = 8khz (defined as narrow band) or 16khz (defined as wide band) only so we have to resample it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0db3dc4-68c8-48c2-bf7e-9073022d9fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage resample to 16khz\n",
    "# input_directory = r'D:/Master/Thesis/FRCRN/Summary/Test/'\n",
    "# output_directory = 'D:/Master/Thesis/FRCRN/Summary/Test resample'\n",
    "# target_sampling_rate = 16000\n",
    "\n",
    "# resample_wav_files(input_directory, output_directory, target_sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e974d8d4-e268-4c9a-b3a7-119ce108b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage Datasets/clean_testset_wav\n",
    "# input_directory = 'D:\\Master\\Thesis\\FRCRN\\CTV bana to add noise\\Bình Định'\n",
    "# output_file = 'D:\\Master\\Thesis\\FRCRN\\CTV bana to add noise\\Bình Định only'\n",
    "\n",
    "# copy_wav_files_to_single_directory(input_directory, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cb578b8-3eaa-49b2-a244-43f39f5233a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'D:/Master/Thesis/FRCRN/Summary/Test resample/0001.1.wav'\n",
    "n = 'D:/Master/Thesis/FRCRN/Summary/Test resample/0001.1_denoised.wav'\n",
    "waveform, sample_rate = torchaudio.load(m)\n",
    "waveform_denoised, sample_rate_denoised = torchaudio.load(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf0a122-193e-48d5-b783-528898772816",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e473ee0f-f080-47b0-9a0c-fb214ff40081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1132)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.audio import PerceptualEvaluationSpeechQuality\n",
    "# pesq = PerceptualEvaluationSpeechQuality(8000, 'nb')\n",
    "# pesq(preds, target)\n",
    "\n",
    "wb_pesq = PerceptualEvaluationSpeechQuality(sample_rate, 'wb')\n",
    "wb_pesq(waveform, waveform_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ff2de43-9b00-4e7a-bd28-26401054f2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9992)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.audio.stoi import ShortTimeObjectiveIntelligibility\n",
    "stoi = ShortTimeObjectiveIntelligibility(sample_rate, False)\n",
    "stoi(waveform, waveform_denoised)\n",
    "#stoi(waveform_denoised, waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5aebea0-5c89-4d14-a5ae-1f9f79e3665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(columns=['PESQ','STOI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f83dda1d-272a-4413-af06-da1204625b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.1.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.1_denoised_FRCRN.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.2.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.2_denoised_FRCRN.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.3.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.3_denoised_FRCRN.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.4.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.4_denoised_FRCRN.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.5.wav\n",
      "D:\\Master\\Thesis\\FRCRN\\Summary\\Test resample\\0001.5_denoised_FRCRN.wav\n"
     ]
    }
   ],
   "source": [
    "for i in bahna_dataset_FRCRN:\n",
    "    print(i)\n",
    "    waveform, sample_rate = torchaudio.load(i)\n",
    "    #normalized_path = os.path.normpath(i)\n",
    "    denoised_path = os.path.splitext(i)[0] + \"_denoised_FRCRN\" + os.path.splitext(i)[1]\n",
    "    waveform_denoised, sample_rate_denoised = torchaudio.load(denoised_path)\n",
    "    print(denoised_path)\n",
    "    wb_pesq = PerceptualEvaluationSpeechQuality(sample_rate, 'wb')\n",
    "    stoi = ShortTimeObjectiveIntelligibility(sample_rate, False)\n",
    "    metric = pd.DataFrame({\"PESQ\":[wb_pesq(waveform, waveform_denoised)],\"STOI\":[stoi(waveform, waveform_denoised)]})\n",
    "    metrics = pd.concat([metrics,metric], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e8f2526-b10c-4f69-89ce-5716af851226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PESQ</th>\n",
       "      <th>STOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(4.1132)</td>\n",
       "      <td>tensor(0.9992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(1.9175)</td>\n",
       "      <td>tensor(0.9248)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(2.6582)</td>\n",
       "      <td>tensor(0.9736)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(2.6803)</td>\n",
       "      <td>tensor(0.9624)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(4.3992)</td>\n",
       "      <td>tensor(0.9952)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PESQ            STOI\n",
       "0  tensor(4.1132)  tensor(0.9992)\n",
       "1  tensor(1.9175)  tensor(0.9248)\n",
       "2  tensor(2.6582)  tensor(0.9736)\n",
       "3  tensor(2.6803)  tensor(0.9624)\n",
       "4  tensor(4.3992)  tensor(0.9952)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612018a-d103-4e38-b5ac-cd0a6f6699d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
